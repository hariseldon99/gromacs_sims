                :-) GROMACS - gmx mdrun, 2024.2-conda_forge (-:

Copyright 1991-2024 The GROMACS Authors.
GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

                         Current GROMACS contributors:
       Mark Abraham           Andrey Alekseenko           Vladimir Basov      
      Cathrine Bergh            Eliane Briand               Ania Brown        
      Mahesh Doijade            Giacomo Fiorin          Stefan Fleischmann    
      Sergey Gorelov         Gilles Gouaillardet            Alan Gray         
     M. Eric Irrgang         Farzaneh Jalalypour            Joe Jordan        
     Carsten Kutzner           Justin A. Lemkul          Magnus Lundborg      
       Pascal Merz              Vedran Miletic            Dmitry Morozov      
       Julien Nabet              Szilard Pall        Andrea Pasquadibisceglie 
    Michele Pellegrino          Hubert Santuz             Roland Schulz       
     Tatiana Shugaeva          Alexey Shvetsov            Philip Turner       
     Alessandra Villa      Sebastian Wingbermuehle  

                         Previous GROMACS contributors:
        Emile Apol             Rossen Apostolov           James Barnett       
        Paul Bauer          Herman J.C. Berendsen          Par Bjelkmar       
      Christian Blau          Viacheslav Bolnykh            Kevin Boyd        
    Aldert van Buuren          Carlo Camilloni           Rudi van Drunen      
      Anton Feenstra           Oliver Fleetwood            Vytas Gapsys       
       Gaurav Garg             Gerrit Groenhof            Bert de Groot       
      Anca Hamuraru           Vincent Hindriksen          Victor Holanda      
     Aleksei Iupinov          Christoph Junghans        Prashanth Kanduri     
   Dimitrios Karkoulis           Peter Kasson             Sebastian Kehl      
     Sebastian Keller             Jiri Kraus               Per Larsson        
      Viveca Lindahl            Erik Marklund           Pieter Meulenhoff     
      Teemu Murtola              Sander Pronk             Michael Shirts      
      Alfons Sijbers            Balint Soproni         David van der Spoel    
      Peter Tieleman            Carsten Uphoff             Jon Vincent        
     Teemu Virolainen         Christian Wennberg           Maarten Wolf       
      Artem Zhmurov       

                  Coordinated by the GROMACS project leaders:
                           Berk Hess and Erik Lindahl

GROMACS:      gmx mdrun, version 2024.2-conda_forge
Executable:   /usr/local/miniforge3/envs/mdanalysis/bin.AVX2_256/gmx
Data prefix:  /usr/local/miniforge3/envs/mdanalysis
Working dir:  /home/daneel/gitrepos/gromacs_sims/zeb_hb/zeb_hb_phz_complex_sim/em
Process ID:   1313781
Command line:
  gmx mdrun -s zeb_hb_phz_complex.tpr -deffnm zeb_hb_phz_complex -nt 12 -ntmpi 0 -nsteps -2 -nocopyright -gpu_id 0

GROMACS version:     2024.2-conda_forge
Precision:           mixed
Memory model:        64 bit
MPI library:         thread_mpi
OpenMP support:      enabled (GMX_OPENMP_MAX_THREADS = 128)
GPU support:         CUDA
NBNxM GPU setup:     super-cluster 2x2x2 / cluster 8
SIMD instructions:   AVX2_256
CPU FFT library:     fftw-3.3.10-sse2-avx
GPU FFT library:     cuFFT
Multi-GPU FFT:       none
RDTSCP usage:        disabled
TNG support:         enabled
Hwloc support:       disabled
Tracing support:     disabled
C compiler:          /home/conda/feedstock_root/build_artifacts/gromacs_1720551881628/_build_env/bin/x86_64-conda-linux-gnu-cc GNU 11.4.0
C compiler flags:    -fexcess-precision=fast -funroll-all-loops -mavx2 -mfma -Wno-missing-field-initializers -O3 -DNDEBUG
C++ compiler:        /home/conda/feedstock_root/build_artifacts/gromacs_1720551881628/_build_env/bin/x86_64-conda-linux-gnu-c++ GNU 11.4.0
C++ compiler flags:  -fexcess-precision=fast -funroll-all-loops -mavx2 -mfma -Wno-missing-field-initializers -Wno-cast-function-type-strict SHELL:-fopenmp -O3 -DNDEBUG
BLAS library:        Internal
LAPACK library:      Internal
CUDA compiler:       /usr/local/cuda/bin/nvcc nvcc: NVIDIA (R) Cuda compiler driver;Copyright (c) 2005-2022 NVIDIA Corporation;Built on Wed_Sep_21_10:33:58_PDT_2022;Cuda compilation tools, release 11.8, V11.8.89;Build cuda_11.8.r11.8/compiler.31833905_0
CUDA compiler flags:-std=c++17;--generate-code=arch=compute_35,code=sm_35;--generate-code=arch=compute_37,code=sm_37;--generate-code=arch=compute_50,code=sm_50;--generate-code=arch=compute_52,code=sm_52;--generate-code=arch=compute_60,code=sm_60;--generate-code=arch=compute_61,code=sm_61;--generate-code=arch=compute_70,code=sm_70;--generate-code=arch=compute_75,code=sm_75;--generate-code=arch=compute_80,code=sm_80;--generate-code=arch=compute_86,code=sm_86;--generate-code=arch=compute_89,code=sm_89;--generate-code=arch=compute_90,code=sm_90;-Wno-deprecated-gpu-targets;--generate-code=arch=compute_53,code=sm_53;--generate-code=arch=compute_80,code=sm_80;-use_fast_math;-Xptxas;-warn-double-usage;-Xptxas;-Werror;;-Xcompiler;-fopenmp;-fexcess-precision=fast -funroll-all-loops -mavx2 -mfma -Wno-missing-field-initializers -Wno-cast-function-type-strict SHELL:-fopenmp -O3 -DNDEBUG
CUDA driver:         12.20
CUDA runtime:        11.80


Running on 1 node with total 6 cores, 12 processing units, 1 compatible GPU
Hardware detected on host sudarshan:
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Core(TM) i7-8750H CPU @ 2.20GHz
    Family: 6   Model: 158   Stepping: 10
    Features: aes apic avx avx2 clfsh cmov cx8 cx16 f16c fma htt intel lahf mmx msr nonstop_tsc pcid pclmuldq pdcm pdpe1gb popcnt pse rdrnd rdtscp sse2 sse3 sse4.1 sse4.2 ssse3 tdt x2apic
  Hardware topology: Basic
    Packages, cores, and logical processors:
    [indices refer to OS logical processors]
      Package  0: [   0   6] [   1   7] [   2   8] [   3   9] [   4  10] [   5  11]
    CPU limit set by OS: -1   Recommended max number of threads: 12
  GPU info:
    Number of GPUs detected: 1
    #0: NVIDIA NVIDIA GeForce GTX 1050, compute cap.: 6.1, ECC:  no, stat: compatible

The current CPU can measure timings more accurately than the code in
gmx mdrun was configured to use. This might affect your simulation
speed as accurate timings are needed for load-balancing.
Please consider rebuilding gmx mdrun with the GMX_USE_RDTSCP=ON CMake option.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
M. J. Abraham, T. Murtola, R. Schulz, S. Páll, J. C. Smith, B. Hess, E.
Lindahl
GROMACS: High performance molecular simulations through multi-level
parallelism from laptops to supercomputers
SoftwareX 1 (2015) pp. 19-25
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Páll, M. J. Abraham, C. Kutzner, B. Hess, E. Lindahl
Tackling Exascale Software Challenges in Molecular Dynamics Simulations with
GROMACS
In S. Markidis & E. Laure (Eds.), Solving Software Challenges for Exascale 8759 (2015) pp. 3-27
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Pronk, S. Páll, R. Schulz, P. Larsson, P. Bjelkmar, R. Apostolov, M. R.
Shirts, J. C. Smith, P. M. Kasson, D. van der Spoel, B. Hess, and E. Lindahl
GROMACS 4.5: a high-throughput and highly parallel open source molecular
simulation toolkit
Bioinformatics 29 (2013) pp. 845-54
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess and C. Kutzner and D. van der Spoel and E. Lindahl
GROMACS 4: Algorithms for highly efficient, load-balanced, and scalable
molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 435-447
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
D. van der Spoel, E. Lindahl, B. Hess, G. Groenhof, A. E. Mark and H. J. C.
Berendsen
GROMACS: Fast, Flexible and Free
J. Comp. Chem. 26 (2005) pp. 1701-1719
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
E. Lindahl and B. Hess and D. van der Spoel
GROMACS 3.0: A package for molecular simulation and trajectory analysis
J. Mol. Mod. 7 (2001) pp. 306-317
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
H. J. C. Berendsen, D. van der Spoel and R. van Drunen
GROMACS: A message-passing parallel molecular dynamics implementation
Comp. Phys. Comm. 91 (1995) pp. 43-56
-------- -------- --- Thank You --- -------- --------

Input Parameters:
   integrator                     = steep
   tinit                          = 0
   dt                             = 0
   nsteps                         = 10000
   init-step                      = 0
   simulation-part                = 1
   mts                            = false
   mass-repartition-factor        = 1
   comm-mode                      = Linear
   nstcomm                        = 100
   bd-fric                        = 0
   ld-seed                        = -68326406
   emtol                          = 10
   emstep                         = 0.01
   niter                          = 20
   fcstep                         = 0
   nstcgsteep                     = 1000
   nbfgscorr                      = 10
   rtpi                           = 0.05
   nstxout                        = 0
   nstvout                        = 0
   nstfout                        = 0
   nstlog                         = 5000
   nstcalcenergy                  = 100
   nstenergy                      = 5000
   nstxout-compressed             = 5000
   compressed-x-precision         = 1000
   cutoff-scheme                  = Verlet
   nstlist                        = 10
   pbc                            = xyz
   periodic-molecules             = false
   verlet-buffer-tolerance        = 0.005
   verlet-buffer-pressure-tolerance = 0.5
   rlist                          = 1.05
   coulombtype                    = PME
   coulomb-modifier               = Potential-shift
   rcoulomb-switch                = 0
   rcoulomb                       = 1
   epsilon-r                      = 1
   epsilon-rf                     = inf
   vdw-type                       = Cut-off
   vdw-modifier                   = Potential-shift
   rvdw-switch                    = 0
   rvdw                           = 1
   DispCorr                       = EnerPres
   table-extension                = 1
   fourierspacing                 = 0.12
   fourier-nx                     = 72
   fourier-ny                     = 72
   fourier-nz                     = 72
   pme-order                      = 4
   ewald-rtol                     = 1e-05
   ewald-rtol-lj                  = 0.001
   lj-pme-comb-rule               = Geometric
   ewald-geometry                 = 3d
   epsilon-surface                = 0
   ensemble-temperature-setting   = not available
   tcoupl                         = No
   nsttcouple                     = -1
   nh-chain-length                = 0
   print-nose-hoover-chain-variables = false
   pcoupl                         = No
   refcoord-scaling               = COM
   posres-com (3):
      posres-com[0]= 0.00000e+00
      posres-com[1]= 0.00000e+00
      posres-com[2]= 0.00000e+00
   posres-comB (3):
      posres-comB[0]= 0.00000e+00
      posres-comB[1]= 0.00000e+00
      posres-comB[2]= 0.00000e+00
   QMMM                           = false
qm-opts:
   ngQM                           = 0
   constraint-algorithm           = Lincs
   continuation                   = false
   Shake-SOR                      = false
   shake-tol                      = 0.0001
   lincs-order                    = 4
   lincs-iter                     = 1
   lincs-warnangle                = 30
   nwall                          = 0
   wall-type                      = 9-3
   wall-r-linpot                  = -1
   wall-atomtype[0]               = -1
   wall-atomtype[1]               = -1
   wall-density[0]                = 0
   wall-density[1]                = 0
   wall-ewald-zfac                = 3
   pull                           = false
   awh                            = false
   rotation                       = false
   interactiveMD                  = false
   disre                          = Simple
   disre-weighting                = Conservative
   disre-mixed                    = false
   dr-fc                          = 1000
   dr-tau                         = 0
   nstdisreout                    = 0
   orire-fc                       = 0
   orire-tau                      = 0
   nstorireout                    = 100
   free-energy                    = no
   cos-acceleration               = 0
   deform (3x3):
      deform[    0]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      deform[    1]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      deform[    2]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
   simulated-tempering            = false
   swapcoords                     = no
   userint1                       = 0
   userint2                       = 0
   userint3                       = 0
   userint4                       = 0
   userreal1                      = 0
   userreal2                      = 0
   userreal3                      = 0
   userreal4                      = 0
   applied-forces:
     electric-field:
       x:
         E0                       = 0
         omega                    = 0
         t0                       = 0
         sigma                    = 0
       y:
         E0                       = 0
         omega                    = 0
         t0                       = 0
         sigma                    = 0
       z:
         E0                       = 0
         omega                    = 0
         t0                       = 0
         sigma                    = 0
     density-guided-simulation:
       active                     = false
       group                      = protein
       similarity-measure         = inner-product
       atom-spreading-weight      = unity
       force-constant             = 1e+09
       gaussian-transform-spreading-width = 0.2
       gaussian-transform-spreading-range-in-multiples-of-width = 4
       reference-density-filename = reference.mrc
       nst                        = 1
       normalize-densities        = true
       adaptive-force-scaling     = false
       adaptive-force-scaling-time-constant = 4
       shift-vector               = 
       transformation-matrix      = 
     qmmm-cp2k:
       active                     = false
       qmgroup                    = System
       qmmethod                   = PBE
       qmfilenames                = 
       qmcharge                   = 0
       qmmultiplicity             = 1
     colvars:
       active                     = false
       configfile                 = 
       seed                       = -1
grpopts:
   nrdf:       65545
   ref-t:           0
   tau-t:           0
annealing:          No
annealing-npoints:           0
   acc:	           0           0           0
   nfreeze:           N           N           N
   energygrp-flags[  0]: 0


Update groups can not be used for this system because there are three or more consecutively coupled constraints

Update task can not run on the GPU, because the following condition(s) were not satisfied:

Only the md integrator is supported.
The number of coupled constraints is higher than supported in the GPU LINCS code.

1 GPU selected for this run.
Mapping of GPU IDs to the 1 GPU task in the 1 rank on this node:
  PP:0
PP tasks will do (non-perturbed) short-ranged interactions on the GPU
PP task will update and constrain coordinates on the CPU
Using 1 MPI thread
Using 12 OpenMP threads 

System total charge: -0.000
Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Coulomb Ewald tables, spacing: 9.33e-04 size: 1073

Generated table with 1025 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1025 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1025 data points for 1-4 LJ12.
Tabscale = 500 points/nm
Long Range LJ corr.: <C6> 3.0958e-04


Using GPU 8x8 nonbonded short-range kernels

Using a 8x8 pair-list setup:
  updated every 10 steps, buffer 0.050 nm, rlist 1.050 nm

Using Lorentz-Berthelot Lennard-Jones combination rule
Removing pbc first time

Pinning threads with an auto-selected logical cpu stride of 1

Initializing LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess and H. Bekker and H. J. C. Berendsen and J. G. E. M. Fraaije
LINCS: A Linear Constraint Solver for molecular simulations
J. Comp. Chem. 18 (1997) pp. 1463-1472
-------- -------- --- Thank You --- -------- --------

The number of constraints is 2261

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------


Note that activating steepest-descent energy minimization via the integrator .mdp option and the command gmx mdrun may be available in a different form in a future version of GROMACS, e.g. gmx minimize and an .mdp option.
Initiating Steepest Descents
Started Steepest Descents on rank 0 Sun Sep 15 21:04:48 2024


Steepest Descents:
   Tolerance (Fmax)   =  1.00000e+01
   Number of steps    =        10000
           Step           Time
              0        0.00000

   Energies (kJ/mol)
          Angle    Proper Dih. Per. Imp. Dih.          LJ-14     Coulomb-14
    1.92446e+03    5.65101e+03    7.01960e+01    2.06235e+03    3.15888e+04
        LJ (SR)  Disper. corr.   Coulomb (SR)   Coul. recip.      Potential
    7.99249e+04   -4.16988e+03   -6.56837e+05    2.27949e+03   -5.37506e+05
 Pres. DC (bar) Pressure (bar)   Constr. rmsd
   -2.07997e+02   -4.88586e+03    6.59654e-04

           Step           Time
              1        1.00000

           Step           Time
              2        2.00000

   Energies (kJ/mol)
          Angle    Proper Dih. Per. Imp. Dih.          LJ-14     Coulomb-14
    1.66576e+03    5.64309e+03    9.01971e+01    2.11084e+03    3.17659e+04
        LJ (SR)  Disper. corr.   Coulomb (SR)   Coul. recip.      Potential
    7.99311e+04   -4.16988e+03   -6.56887e+05    2.27620e+03   -5.37573e+05
 Pres. DC (bar) Pressure (bar)   Constr. rmsd
   -2.07997e+02   -4.60489e+03    7.39078e-04

           Step           Time
              3        3.00000

   Energies (kJ/mol)
          Angle    Proper Dih. Per. Imp. Dih.          LJ-14     Coulomb-14
    1.71053e+03    5.65108e+03    7.52921e+01    2.13771e+03    3.17623e+04
        LJ (SR)  Disper. corr.   Coulomb (SR)   Coul. recip.      Potential
    7.99199e+04   -4.16988e+03   -6.56958e+05    2.27448e+03   -5.37596e+05
 Pres. DC (bar) Pressure (bar)   Constr. rmsd
   -2.07997e+02   -4.73151e+03    3.57353e-04

           Step           Time
              4        4.00000

           Step           Time
              5        5.00000

   Energies (kJ/mol)
          Angle    Proper Dih. Per. Imp. Dih.          LJ-14     Coulomb-14
    1.63505e+03    5.63436e+03    7.24804e+01    2.14558e+03    3.17772e+04
        LJ (SR)  Disper. corr.   Coulomb (SR)   Coul. recip.      Potential
    7.99214e+04   -4.16988e+03   -6.56949e+05    2.27519e+03   -5.37657e+05
 Pres. DC (bar) Pressure (bar)   Constr. rmsd
   -2.07997e+02   -4.69673e+03    2.09038e-04

           Step           Time
              6        6.00000

   Energies (kJ/mol)
          Angle    Proper Dih. Per. Imp. Dih.          LJ-14     Coulomb-14
    1.55460e+03    5.64190e+03    7.53046e+01    2.17724e+03    3.17992e+04
        LJ (SR)  Disper. corr.   Coulomb (SR)   Coul. recip.      Potential
    7.99602e+04   -4.16988e+03   -6.57012e+05    2.27290e+03   -5.37700e+05
 Pres. DC (bar) Pressure (bar)   Constr. rmsd
   -2.07997e+02   -4.58795e+03    8.07352e-04

           Step           Time
              7        7.00000

           Step           Time
              8        8.00000

           Step           Time
              9        9.00000

           Step           Time
             10       10.00000

           Step           Time
             11       11.00000

           Step           Time
             12       12.00000

           Step           Time
             13       13.00000

           Step           Time
             14       14.00000

           Step           Time
             15       15.00000

           Step           Time
             16       16.00000

           Step           Time
             17       17.00000

           Step           Time
             18       18.00000

           Step           Time
             19       19.00000


Energy minimization has stopped, but the forces have not converged to the
requested precision Fmax < 10 (which may not be possible for your system). It
stopped because the algorithm tried to make a new step whose size was too
small, or there was no change in the energy since last step. Either way, we
regard the minimization as converged to within the available machine
precision, given your starting configuration and EM parameters.

Double precision normally gives you higher accuracy, but this is often not
needed for preparing to run molecular dynamics.
You might need to increase your constraint accuracy, or turn
off constraints altogether (set constraints = none in mdp file)

Steepest Descents converged to machine precision in 20 steps,
but did not reach the requested Fmax < 10.
Potential Energy  = -5.3770050e+05
Maximum force     =  9.0150006e+02 on atom 1143
Norm of force     =  3.2872761e+01
Finished mdrun on rank 0 Sun Sep 15 21:04:48 2024

